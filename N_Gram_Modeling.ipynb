{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I063\n",
        "\n",
        "KAUSHIKA SEMWAL\n",
        "\n",
        "BATCH 2"
      ],
      "metadata": {
        "id": "Wc7MZZPpnu9k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c13352d"
      },
      "source": [
        "# Task\n",
        "Build a sentence generator using n-gram modeling. The model should take the first two words of a sentence as input and generate a syntactically coherent sentence of at least 10–12 words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h86yqy9JoRAO",
        "outputId": "969eca3d-62d2-40bc-d401-9621c8432a06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import nltk\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "2i1v-Xp1r2jL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBMX-aVDr3CZ",
        "outputId": "c99273f8-2cf6-4f82-d8aa-3300a565360a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading and preprocessing text from URL...\")\n",
        "url = \"https://www.gutenberg.org/cache/epub/1513/pg1513.txt\"\n",
        "raw_text = requests.get(url).text.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTioUDBjsdkc",
        "outputId": "72154875-146e-4173-c403-7782af27f561"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing text from URL...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_marker = \"*** start of the project gutenberg ebook\"\n",
        "end_marker = \"end of the project gutenberg ebook\"\n",
        "raw_text = raw_text[raw_text.find(start_marker) + len(start_marker):raw_text.find(end_marker)]\n",
        "\n",
        "# Tokenize and clean the text\n",
        "tokens = word_tokenize(raw_text)\n",
        "tokens = [token for token in tokens if re.match(r'^[a-z]+$', token)]\n",
        "print(\"Data loaded and preprocessed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rQya-XbsfzM",
        "outputId": "be2ef97f-f085-4871-d731-97a04a33a63c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram_model(tokens, n):\n",
        "    \"\"\"Builds a model that maps a history of (n-1) words to a counter of following words.\"\"\"\n",
        "    model = defaultdict(Counter)\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        history = tuple(tokens[i : i + n - 1])\n",
        "        next_word = tokens[i + n - 1]\n",
        "        model[history][next_word] += 1\n",
        "    return model"
      ],
      "metadata": {
        "id": "oob-89i-tKWg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building n-gram models on Shakespeare's text...\")\n",
        "bigram_model = build_ngram_model(tokens, 2)\n",
        "trigram_model = build_ngram_model(tokens, 3)\n",
        "fourgram_model = build_ngram_model(tokens, 4)\n",
        "print(\"N-gram models built successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSvSzGxstNbn",
        "outputId": "03dbf19a-521f-4f64-c5ed-5814faa24f7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building n-gram models on Shakespeare's text...\n",
            "N-gram models built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence_with_backoff(start_words, max_length=15):\n",
        "    \"\"\"Generates a sentence using a back-off strategy.\"\"\"\n",
        "    words = start_words.lower().split()\n",
        "\n",
        "    # Pad the beginning if the input is too short for the 4-gram model\n",
        "    if len(words) < 3:\n",
        "        # Using a common word from the text like 'the' for padding\n",
        "        words = ['the'] * (3 - len(words)) + words\n",
        "\n",
        "    for _ in range(max_length - len(start_words.split())):\n",
        "        next_word = None\n",
        "        # Try 4-gram model (history of 3 words)\n",
        "        history_4gram = tuple(words[-3:])\n",
        "        if history_4gram in fourgram_model:\n",
        "            options = fourgram_model[history_4gram]\n",
        "            next_word = random.choices(list(options.keys()), weights=list(options.values()))[0]\n",
        "\n",
        "        # Back off to Trigram model (history of 2 words)\n",
        "        if not next_word:\n",
        "            history_trigram = tuple(words[-2:])\n",
        "            if history_trigram in trigram_model:\n",
        "                options = trigram_model[history_trigram]\n",
        "                next_word = random.choices(list(options.keys()), weights=list(options.values()))[0]\n",
        "\n",
        "        # Back off to Bigram model (history of 1 word)\n",
        "        if not next_word:\n",
        "            history_bigram = tuple(words[-1:])\n",
        "            if history_bigram in bigram_model:\n",
        "                options = bigram_model[history_bigram]\n",
        "                next_word = random.choices(list(options.keys()), weights=list(options.values()))[0]\n",
        "\n",
        "        # Last resort: pick a random word from the text\n",
        "        if not next_word:\n",
        "            next_word = random.choice(tokens)\n",
        "\n",
        "        words.append(next_word)\n",
        "\n",
        "    final_sentence = start_words + ' ' + ' '.join(words[len(start_words.split()):])\n",
        "    return final_sentence.capitalize() + '.'"
      ],
      "metadata": {
        "id": "SOaa4Yq9tRRQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"<h1>🖋️ The Shakespeare Engine (Romeo and Juliet)</h1>\")\n",
        "    gr.Markdown(\"<p>This model generates sentences that mimic the writing style of Shakespeare. Enter a word or two to begin.</p>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        start_words_input = gr.Textbox(\n",
        "            lines=1,\n",
        "            placeholder=\"e.g., O Romeo\",\n",
        "            label=\"Starting Words\"\n",
        "        )\n",
        "\n",
        "    generate_button = gr.Button(\"Generate Sentence\")\n",
        "    output_text = gr.Textbox(label=\"Generated Sentence\")\n",
        "\n",
        "    generate_button.click(\n",
        "        fn=generate_sentence_with_backoff,\n",
        "        inputs=start_words_input,\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "MNTo2Udxw03D",
        "outputId": "8b47c86c-b387-411e-d37a-edc5d894bfc4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e77625c1ef19770a6f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e77625c1ef19770a6f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e77625c1ef19770a6f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}